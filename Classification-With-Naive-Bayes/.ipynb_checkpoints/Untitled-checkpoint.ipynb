{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1: Classification With Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p1\n",
    "#Read the data using pandas. Skip first row. There are a total of 767 data-points.\n",
    "pid_df = pd.read_csv(\"pima-indians-diabetes.csv\", skiprows = [0], names = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\", \"Class\"])\n",
    "\n",
    "#General classifier class.\n",
    "class Classifier(object):\n",
    "    def __init__(self, train_df, test_df):\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "    def train(self):\n",
    "        pass\n",
    "    def predict(self):\n",
    "        pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7483830107762113\n"
     ]
    }
   ],
   "source": [
    "#p1\n",
    "#naive Bayes classifier\n",
    "class NBC(Classifier):\n",
    "    def __init__(self, df, missing = False):\n",
    "        super().__init__(*self.split(df))\n",
    "        self.missing = missing\n",
    "        \n",
    "    def train(self):\n",
    "        #calculate the prior probabilities.\n",
    "        p_prior = {}\n",
    "        for index, example in self.train_df.iterrows():\n",
    "            p_prior[example[\"Class\"]] = p_prior.get(example[\"Class\"], 0) + 1\n",
    "        assert sum(p_prior.values()) == len(self.train_df), \"failed to compute the prior\"\n",
    "        for key in p_prior:\n",
    "            p_prior[key] = p_prior[key]/len(self.train_df)\n",
    "        self.p_prior = p_prior\n",
    "        \n",
    "        #calculate the likelihood normal distributions.\n",
    "        p_likelihood = {}\n",
    "        for col in list(self.train_df)[:-1]:\n",
    "            p_likelihood[col] = {}\n",
    "            for class_value in p_prior:\n",
    "                values = self.train_df.loc[self.train_df[\"Class\"] == class_value, col].values\n",
    "                mean, std = np.mean(values), np.std(values)\n",
    "                p_likelihood[col][class_value] = norm(mean, std)\n",
    "        self.p_likelihood = p_likelihood\n",
    "        return self\n",
    "    \n",
    "    def predict(self):\n",
    "        self.res = {}\n",
    "        for index, example in self.test_df.iterrows():\n",
    "            log_p_predict = {class_value:np.log(self.p_prior[class_value]) for class_value in self.p_prior}\n",
    "            for col in list(self.train_df)[:-1]:\n",
    "                for class_value in self.p_prior:\n",
    "                    log_p_predict[class_value] += np.log(self.p_likelihood[col][class_value].pdf(example[col]))\n",
    "            self.res[index] = max(log_p_predict, key=log_p_predict.get)\n",
    "        return self\n",
    "    \n",
    "    def get_acc(self):\n",
    "        cnt = 0 \n",
    "        for index, example in self.test_df.iterrows():\n",
    "            cnt += 1 if example[\"Class\"] == self.res[index] else 0\n",
    "        return cnt/len(self.test_df)\n",
    "                        \n",
    "    # split the data, 20% for testing, rest for training.\n",
    "    def split(self, df):\n",
    "        msk = np.random.rand(len(df)) < 0.8\n",
    "        train = df[msk]\n",
    "        test = df[~msk]\n",
    "        return train, test\n",
    "\n",
    "#p1.a\n",
    "#calculate the average over 10 splits\n",
    "num_splits = 10\n",
    "print(sum([NBC(pid_df).train().predict().get_acc() for _ in range(num_splits)])/num_splits)\n",
    "\n",
    "#p1.b\n",
    "num_splits = 10\n",
    "print(sum([NBC(pid_df, missing = True).train().predict().get_acc() for _ in range(num_splits)])/num_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies\n",
      "Glucose\n",
      "BloodPressure\n",
      "SkinThickness\n",
      "Insulin\n",
      "BMI\n",
      "DiabetesPedigreeFunction\n",
      "Age\n",
      "Class\n"
     ]
    }
   ],
   "source": [
    "#p1.b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
